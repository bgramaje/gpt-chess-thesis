{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in /home/bgramaje/.local/lib/python3.10/site-packages (0.27.6)\n",
      "Requirement already satisfied: tqdm in /home/bgramaje/.local/lib/python3.10/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: requests>=2.20 in /home/bgramaje/.local/lib/python3.10/site-packages (from openai) (2.28.2)\n",
      "Requirement already satisfied: aiohttp in /home/bgramaje/.local/lib/python3.10/site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/bgramaje/.local/lib/python3.10/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/bgramaje/.local/lib/python3.10/site-packages (from requests>=2.20->openai) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/bgramaje/.local/lib/python3.10/site-packages (from requests>=2.20->openai) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/bgramaje/.local/lib/python3.10/site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/bgramaje/.local/lib/python3.10/site-packages (from aiohttp->openai) (22.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/bgramaje/.local/lib/python3.10/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/bgramaje/.local/lib/python3.10/site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/bgramaje/.local/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/bgramaje/.local/lib/python3.10/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/bgramaje/.local/lib/python3.10/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: chess in /home/bgramaje/.local/lib/python3.10/site-packages (1.9.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/bgramaje/.local/lib/python3.10/site-packages (1.3.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/bgramaje/.local/lib/python3.10/site-packages (from scikit-learn) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/bgramaje/.local/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/bgramaje/.local/lib/python3.10/site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/bgramaje/.local/lib/python3.10/site-packages (from scikit-learn) (1.11.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai\n",
    "%pip install chess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import os\n",
    "import openai\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import chess\n",
    "import copy\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "\n",
    "from ast import literal_eval\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe from downloaded dataset\n",
    "df = pd.read_csv('data/db.csv')\n",
    "# create dataframe of one move chess puzzles\n",
    "df_one = df[df['Themes'].str.contains('mateIn1')].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['babbage', 'text-davinci-003', 'davinci', 'text-davinci-edit-001', 'babbage-code-search-code', 'text-similarity-babbage-001', 'code-davinci-edit-001', 'ada', 'babbage-code-search-text', 'babbage-similarity', 'gpt-3.5-turbo-16k-0613', 'code-search-babbage-text-001', 'text-curie-001', 'gpt-3.5-turbo-0301', 'gpt-3.5-turbo-16k', 'code-search-babbage-code-001', 'text-ada-001', 'text-similarity-ada-001', 'text-davinci-002', 'curie-instruct-beta', 'ada-code-search-code', 'ada-similarity', 'code-search-ada-text-001', 'text-search-ada-query-001', 'davinci-search-document', 'ada-code-search-text', 'text-search-ada-doc-001', 'davinci-instruct-beta', 'text-similarity-curie-001', 'code-search-ada-code-001', 'ada-search-query', 'text-search-davinci-query-001', 'curie-search-query', 'davinci-search-query', 'babbage-search-document', 'ada-search-document', 'text-search-curie-query-001', 'text-babbage-001', 'text-search-babbage-doc-001', 'whisper-1', 'curie-search-document', 'text-davinci-001', 'text-search-curie-doc-001', 'babbage-search-query', 'text-search-davinci-doc-001', 'text-search-babbage-query-001', 'curie-similarity', 'text-embedding-ada-002', 'curie', 'text-similarity-davinci-001', 'gpt-3.5-turbo-0613', 'davinci-similarity', 'gpt-3.5-turbo']\n"
     ]
    }
   ],
   "source": [
    "# import environment variable into notebook\n",
    "_ = load_dotenv(find_dotenv())  # read local .env file\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY_UPV')\n",
    "\n",
    "# list openai available models given the api key.\n",
    "ids = [item[\"id\"] for item in (openai.Model.list())['data']]\n",
    "print(ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_move(board: chess.Board, move: chess.Move):\n",
    "    \"\"\" \n",
    "    args:\n",
    "        board (chess.Board)\n",
    "        moves (chess.Move)\n",
    "    \"\"\"\n",
    "    if board.is_legal(move):\n",
    "        board.push(move)\n",
    "    return board\n",
    "\n",
    "\n",
    "def is_legal_move(board: chess.Board, move: chess.Move) -> bool:\n",
    "    \"\"\" \n",
    "    Function that given a fen an a move checks\n",
    "    if the provided move is legal\n",
    "    args:\n",
    "        board (chess.Board)\n",
    "        moves (str)\n",
    "    returns:\n",
    "        bool  \n",
    "    \"\"\"\n",
    "    return board.is_legal(move)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_filename(template, temperature, dir, model, ext=\"txt\"):\n",
    "    \"\"\"\n",
    "        generate filename name, if it exists, it appends an index number\n",
    "        at the end of it.\n",
    "    \"\"\"\n",
    "    current_date = datetime.datetime.now().strftime(\"%d_%m\")\n",
    "    filename = f\"{current_date}-{template}-{model}-{temperature}.{ext}\"\n",
    "    full_path = os.path.join(dir, filename)\n",
    "\n",
    "    index = 1\n",
    "    while os.path.exists(full_path):\n",
    "        new_filename = f\"{current_date}-{template}-{model}-{temperature}_{index}.{ext}\"\n",
    "        full_path = os.path.join(dir, new_filename)\n",
    "        index += 1\n",
    "\n",
    "    return full_path\n",
    "\n",
    "\n",
    "def build_columns(variability=3):\n",
    "    columns = []\n",
    "\n",
    "    columns.append(f\"puzzleId\")\n",
    "    columns.append(f\"datasetMove\")\n",
    "\n",
    "    for i in range(variability):\n",
    "        columns.append(f\"gpt{i}-move\")\n",
    "        columns.append(f\"gpt{i}-valid\")\n",
    "        columns.append(f\"gpt{i}-done\")\n",
    "\n",
    "    columns.append(f\"gpt-results\")\n",
    "    return columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dataframe that with the provided moves, the puzzle is completed\n",
    "# should be a redundant code as the dataset should be all puzzles completed\n",
    "# but just in case of some puzzle stored not done correctly.\n",
    "\n",
    "checkmate_df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "for index, row in df_one.iterrows():\n",
    "    board = chess.Board(row['FEN'])\n",
    "    chess_moves = [chess.Move.from_uci(move) for move in row['Moves'].split()]\n",
    "\n",
    "    for move in chess_moves:\n",
    "        if (move in board.legal_moves):\n",
    "            push_move(board=board, move=move)\n",
    "\n",
    "    if (board.is_checkmate()):\n",
    "        checkmate_df = pd.concat([checkmate_df, row.to_frame().T])\n",
    "    else:\n",
    "        print(row['PuzzleId'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global constant variables\n",
    "\n",
    "# output dir to save data files\n",
    "OUTPUT_DIR = \"./out\"\n",
    "# name of files to append to filename\n",
    "TEMPLATE_FILE_PATH = \"data\"\n",
    "# type of extension for data files\n",
    "EXTENSION_FILE = \"csv\"\n",
    "\n",
    "# error files dir path\n",
    "OUTPUT_ERROR_DIR = \"./out/error\"\n",
    "# name of error files to append to error filename\n",
    "TEMPLATE_ERROR_FILE_PATH = \"error\"\n",
    "\n",
    "# openai variables\n",
    "\n",
    "TEMPERATURE = 0\n",
    "# AVAILABLE MODELS [gpt-3.5-turbo-16k, gpt-4, gpt-4-0613]\n",
    "MODEL = 'gpt-3.5-turbo-16k'\n",
    "\n",
    "# config variables\n",
    "\n",
    "# increase time in case of error *`ServiceUnavailableError: The server is overloaded or not ready yet.`*\n",
    "REQ_INTERVAL = 5  # 10 sec\n",
    "VARIABILITY_TRIES = 3\n",
    "MAX_PUZZLES = 5\n",
    "\n",
    "# debug flag\n",
    "DEBUG = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request(\n",
    "    prompt=\"\",\n",
    "    context=np.array([]),\n",
    "):\n",
    "    \"\"\"\n",
    "    Helper function to make a request to openai api, and return it's response.\n",
    "    args:\n",
    "        prompt (string)\n",
    "        model (str)\n",
    "        temperature (int)\n",
    "    returns:\n",
    "        str\n",
    "    \"\"\"\n",
    "    context = np.append(\n",
    "        context,\n",
    "        np.array([{\n",
    "            \"role\": 'user',\n",
    "            \"content\": f\"\"\"\n",
    "                {prompt}\n",
    "            \"\"\",\n",
    "        }]), axis=0)\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=MODEL,\n",
    "        messages=context.tolist(),\n",
    "        temperature=TEMPERATURE,  # this is the degree of randomness of the model's output\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message[\"content\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_row(row, context, temperature=0, debug=False):\n",
    "    # create chess board with 'fen' dataset\n",
    "    board = chess.Board(row['FEN'])\n",
    "    # create chess moves from 'uci' moves from dataset\n",
    "    chess_moves = [chess.Move.from_uci(move) for move in row['Moves'].split()]\n",
    "    # retrieve last move\n",
    "    last_move = chess_moves.pop()\n",
    "\n",
    "    # add all moves except the last one.\n",
    "    for move in chess_moves:\n",
    "        push_move(board=board, move=move)\n",
    "\n",
    "    # generate prompt\n",
    "    prompt = f\"\"\"\n",
    "        \"fen\": {board.fen()}\n",
    "        \"valid_moves\": { json.dumps([move.uci() for move in list(board.legal_moves)])}\n",
    "    \"\"\"\n",
    "\n",
    "    # req to gpt model\n",
    "    req = request(prompt=prompt, context=context).replace(\" \", \"\")\n",
    "\n",
    "    if (debug):\n",
    "        print(f\"[gpt-response]: {req}\")\n",
    "\n",
    "    res = literal_eval(req)\n",
    "    # check if valid gpt res move\n",
    "    valid_res = is_legal_move(\n",
    "        board=board, move=chess.Move.from_uci(res['move']))\n",
    "\n",
    "    # info printings\n",
    "    if (debug):\n",
    "        print(f\"[gpt-move | dataset-move] : {res['move']} | {last_move}\")\n",
    "\n",
    "    if (valid_res is not True):\n",
    "        return {\n",
    "            \"completed\": False,\n",
    "            \"move\": res['move'],\n",
    "            \"valid\": valid_res\n",
    "        }\n",
    "\n",
    "    board_gpt = push_move(board=copy.deepcopy(\n",
    "        board), move=chess.Move.from_uci(res['move']))\n",
    "\n",
    "    return {\n",
    "        \"completed\": board_gpt.is_checkmate(),\n",
    "        \"move\": res['move'],\n",
    "        \"valid\": valid_res\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = np.array([])\n",
    "\n",
    "# for training-dataset purposes\n",
    "# for index, row in train_df_one.iterrows():\n",
    "#     context = np.append(context, process_training_row(row))\n",
    "\n",
    "messages = np.array([\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"\"\"      \n",
    "                You are a chess engine playing that solves chess puzzles. \\\n",
    "                Your main task will be to solve chess puzzles.\n",
    "                \n",
    "                Therefore, I will provide you with board position in \\\n",
    "                'FEN (Forsythâ€“Edwards Notation)' format. Also all the \\\n",
    "                legal moves available for that FEN board in UCI (Universal \\\n",
    "                Chess Interface) format.\n",
    "                \n",
    "                The prompt input structure will be something like this:\n",
    "                \n",
    "                ```\n",
    "                    \"fen\": <fen>\n",
    "                    \"valid_moves\" : <valid_moves>\n",
    "                ```\n",
    "                \n",
    "                Your task is to choose one of the moves from the legal \\\n",
    "                moves list provided in the prompt that produces a mate \\ \n",
    "                in one to the provided FEN\n",
    "                                \n",
    "                Please do not provide any extra definition or information, just output \\\n",
    "                the movement in a JSON Object with the following format:\n",
    "                \n",
    "                ```\n",
    "                    \"move\": <your_move>\n",
    "                ```\n",
    "            \"\"\",\n",
    "    },\n",
    "])\n",
    "\n",
    "context = np.append(messages, context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[exp-path] : ./out/26_07-data2-gpt-3.5-turbo-16k-0_1.csv\n",
      "[error-exp-path] : ./out/error/26_07-error-gpt-3.5-turbo-16k-0.txt\n",
      "[001gi]: ['001gi', 'a5c3', 'h8g8', True, False, 'h8g8', True, False, 'h8g8', True, False, 'False False False']\n",
      "[001wb]: ['001wb', 'g6h5', 'h8g8', True, False, 'h8g8', True, False, 'h8g8', True, False, 'False False False']\n",
      "[002CP]: ['002CP', 'g6c2', 'g6f7', True, False, 'g6f7', True, False, 'g6f7', True, False, 'False False False']\n",
      "[003IX]: ['003IX', 'e4g3', 'e7f8', True, False, 'e7f8', True, False, 'e7f8', True, False, 'False False False']\n",
      "[004iZ]: ['004iZ', 'g3g7', 'd4g7', True, False, 'd4g7', True, False, 'd4g7', True, False, 'False False False']\n",
      "Finished experiment and stored at ./out/26_07-data2-gpt-3.5-turbo-16k-0_1.csv\n"
     ]
    }
   ],
   "source": [
    "filename = build_filename(\n",
    "    template=TEMPLATE_FILE_PATH,\n",
    "    temperature=TEMPERATURE,\n",
    "    dir=OUTPUT_DIR,\n",
    "    model=MODEL,\n",
    "    ext=EXTENSION_FILE\n",
    ")\n",
    "\n",
    "error_filename = build_filename(\n",
    "    template=TEMPLATE_ERROR_FILE_PATH,\n",
    "    temperature=TEMPERATURE,\n",
    "    dir=OUTPUT_ERROR_DIR,\n",
    "    model=MODEL,\n",
    ")\n",
    "\n",
    "print(f\"[exp-path] : {filename}\")\n",
    "print(f\"[error-exp-path] : {error_filename}\")\n",
    "\n",
    "_df = pd.DataFrame(columns=build_columns(VARIABILITY_TRIES))\n",
    "\n",
    "try:\n",
    "    FILE = open(filename, 'w')\n",
    "    for index, row in checkmate_df.iterrows():\n",
    "        try:\n",
    "            # only first 100 rows [testing]\n",
    "            if (index == MAX_PUZZLES):\n",
    "                break\n",
    "\n",
    "            # list to store results\n",
    "            results = []\n",
    "            final_column = []\n",
    "            # store puzzle id\n",
    "            results.append(row['PuzzleId'])\n",
    "            # store dataset last move\n",
    "            results.append(row['Moves'].split().pop())\n",
    "\n",
    "            # 3 iterations for variability purposes\n",
    "            for i in range(VARIABILITY_TRIES):\n",
    "                result = process_test_row(\n",
    "                    row=row, context=context, debug=False)\n",
    "                results.append(result['move'])\n",
    "                results.append(result['valid'])\n",
    "                results.append(result['completed'])\n",
    "                final_column.append(result['completed'])\n",
    "\n",
    "                if (\"gpt-4\" in MODEL):\n",
    "                    time.sleep(REQ_INTERVAL)\n",
    "\n",
    "            results.append(' '.join(str(e) for e in final_column))\n",
    "\n",
    "            if (DEBUG is True):\n",
    "                print(f\"[{row['PuzzleId']}]: { results }\")\n",
    "\n",
    "            _df.loc[len(_df)] = results\n",
    "        except Exception as e:                    \n",
    "            if (DEBUG is True):\n",
    "                print(f\"[{row['PuzzleId']}]: { e }\")\n",
    "            \n",
    "            ERROR_FILE = open(error_filename, 'w')\n",
    "            ERROR_FILE.write(f\"[{row['PuzzleId']}]: { e }\\n\")\n",
    "            ERROR_FILE.close()\n",
    "\n",
    "    print(f\"Finished experiment and stored at {filename}\")\n",
    "except Exception as e:\n",
    "    if (DEBUG is True):\n",
    "        print(f\"{ e }\\n\")\n",
    "        \n",
    "_df.to_csv(filename, index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

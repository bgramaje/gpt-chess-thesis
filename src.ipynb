{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in /home/bgramaje/.local/lib/python3.10/site-packages (0.27.6)\n",
      "Requirement already satisfied: aiohttp in /home/bgramaje/.local/lib/python3.10/site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: tqdm in /home/bgramaje/.local/lib/python3.10/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: requests>=2.20 in /home/bgramaje/.local/lib/python3.10/site-packages (from openai) (2.28.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/bgramaje/.local/lib/python3.10/site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/bgramaje/.local/lib/python3.10/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/bgramaje/.local/lib/python3.10/site-packages (from requests>=2.20->openai) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/bgramaje/.local/lib/python3.10/site-packages (from requests>=2.20->openai) (1.26.14)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/bgramaje/.local/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/bgramaje/.local/lib/python3.10/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/bgramaje/.local/lib/python3.10/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/bgramaje/.local/lib/python3.10/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/bgramaje/.local/lib/python3.10/site-packages (from aiohttp->openai) (22.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/bgramaje/.local/lib/python3.10/site-packages (from aiohttp->openai) (1.3.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: chess in /home/bgramaje/.local/lib/python3.10/site-packages (1.9.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/bgramaje/.local/lib/python3.10/site-packages (1.3.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/bgramaje/.local/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/bgramaje/.local/lib/python3.10/site-packages (from scikit-learn) (1.11.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/bgramaje/.local/lib/python3.10/site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/bgramaje/.local/lib/python3.10/site-packages (from scikit-learn) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai\n",
    "%pip install chess\n",
    "%pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import os\n",
    "import openai\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import chess\n",
    "import copy\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "\n",
    "from ast import literal_eval\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global constant variables\n",
    "OUTPUT_DIR = \"./out\"\n",
    "TEMPLATE_FILE_PATH = \"data\"\n",
    "\n",
    "OUTPUT_ERROR_DIR = \"./out/error\"\n",
    "TEMPLATE_ERROR_FILE_PATH = \"error\"\n",
    "# openai variables\n",
    "TEMPERATURE = 0\n",
    "MODEL = 'gpt-3.5-turbo-16k'\n",
    "\n",
    "# debug flag\n",
    "DEBUG = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['whisper-1', 'babbage', 'text-davinci-003', 'davinci', 'text-davinci-edit-001', 'babbage-code-search-code', 'text-similarity-babbage-001', 'code-davinci-edit-001', 'text-davinci-001', 'ada', 'babbage-code-search-text', 'babbage-similarity', 'gpt-3.5-turbo-16k-0613', 'code-search-babbage-text-001', 'text-curie-001', 'gpt-3.5-turbo-0301', 'gpt-3.5-turbo-16k', 'code-search-babbage-code-001', 'text-ada-001', 'text-similarity-ada-001', 'curie-instruct-beta', 'ada-code-search-code', 'ada-similarity', 'code-search-ada-text-001', 'text-search-ada-query-001', 'davinci-search-document', 'ada-code-search-text', 'text-search-ada-doc-001', 'davinci-instruct-beta', 'text-similarity-curie-001', 'code-search-ada-code-001', 'ada-search-query', 'text-search-davinci-query-001', 'curie-search-query', 'davinci-search-query', 'babbage-search-document', 'ada-search-document', 'text-search-curie-query-001', 'text-search-babbage-doc-001', 'curie-search-document', 'text-search-curie-doc-001', 'babbage-search-query', 'text-babbage-001', 'text-search-davinci-doc-001', 'gpt-3.5-turbo', 'text-search-babbage-query-001', 'curie-similarity', 'text-davinci-002', 'gpt-3.5-turbo-0613', 'text-embedding-ada-002', 'curie', 'text-similarity-davinci-001', 'davinci-similarity']\n"
     ]
    }
   ],
   "source": [
    "# import environment variable into notebook\n",
    "_ = load_dotenv(find_dotenv())  # read local .env file\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY_UPV')\n",
    "# openai.api_key = <INSERT_API_KEY_HERE>\n",
    "\n",
    "# list openai available models given the api key.\n",
    "ids = [item[\"id\"] for item in (openai.Model.list())['data']]\n",
    "print(ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request(\n",
    "    prompt=\"\",\n",
    "    context=np.array([])\n",
    "):\n",
    "    \"\"\"\n",
    "    Helper function to make a request to openai api, and return it's response.\n",
    "    args:\n",
    "        prompt (string)\n",
    "        model (str)\n",
    "        temperature (int)\n",
    "    returns:\n",
    "        str\n",
    "    \"\"\"\n",
    "    context = np.append(\n",
    "        context,\n",
    "        np.array([{\n",
    "            \"role\": 'user',\n",
    "            \"content\": f\"\"\"\n",
    "                {prompt}\n",
    "            \"\"\",\n",
    "        }]), axis=0)\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=MODEL,\n",
    "        messages=context.tolist(),\n",
    "        temperature=TEMPERATURE,  # this is the degree of randomness of the model's output\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message[\"content\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe from downloaded dataset\n",
    "df = pd.read_csv('data/db.csv')\n",
    "# create dataframe of one move chess puzzles\n",
    "df_one = df[df['Themes'].str.contains('mateIn1')].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training dataset builder\n",
    "\n",
    "# train_df_one, test_df_one = train_test_split(\n",
    "#     df_one, test_size=0.9999, random_state=42)\n",
    "\n",
    "# train_df_one = train_df_one.reset_index(drop=True)\n",
    "# test_df_one = test_df_one.reset_index(drop=True)\n",
    "\n",
    "# print(len(train_df_one))\n",
    "\n",
    "# training function row for training purposes\n",
    "# def process_training_row(row):\n",
    "#     board = chess.Board(row['FEN'])\n",
    "#     move = chess.Move.from_uci(row['Moves'].split()[0])\n",
    "#     board.push(move)\n",
    "\n",
    "#     valid_moves = list(board.legal_moves)\n",
    "\n",
    "#     return np.array([\n",
    "#         {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": json.dumps({\n",
    "#                 \"fen\": board.fen(),\n",
    "#                 \"valid_moves\": [move.uci() for move in valid_moves]\n",
    "#             })\n",
    "#         }, {\n",
    "#             \"role\": \"assistant\",\n",
    "#             \"content\": json.dumps({\n",
    "#                 \"move\": row['Moves'].split()[1]\n",
    "#             })\n",
    "#         }\n",
    "#     ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_move(board: chess.Board, move: chess.Move):\n",
    "    \"\"\" \n",
    "    args:\n",
    "        board (chess.Board)\n",
    "        moves (chess.Move)\n",
    "    \"\"\"\n",
    "    if board.is_legal(move):\n",
    "        board.push(move)\n",
    "    return board\n",
    "\n",
    "\n",
    "def is_legal_move(board: chess.Board, move: chess.Move) -> bool:\n",
    "    \"\"\" \n",
    "    Function that given a fen an a move checks\n",
    "    if the provided move is legal\n",
    "    args:\n",
    "        board (chess.Board)\n",
    "        moves (str)\n",
    "    returns:\n",
    "        bool  \n",
    "    \"\"\"\n",
    "    return board.is_legal(move)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_row(row, context, temperature=0, debug=False):\n",
    "    # create chess board with 'fen' dataset\n",
    "    board = chess.Board(row['FEN'])\n",
    "    # create chess moves from 'uci' moves from dataset\n",
    "    chess_moves = [chess.Move.from_uci(move) for move in row['Moves'].split()]\n",
    "    # retrieve last move\n",
    "    last_move = chess_moves.pop()\n",
    "\n",
    "    # add all moves except the last one.\n",
    "    for move in chess_moves:\n",
    "        push_move(board=board, move=move)\n",
    "\n",
    "    # generate prompt\n",
    "    prompt = f\"\"\"\n",
    "        \"fen\": {board.fen()}\n",
    "        \"valid_moves\": { json.dumps([move.uci() for move in list(board.legal_moves)])}\n",
    "    \"\"\"\n",
    "\n",
    "    # req to gpt model\n",
    "    req = request(prompt=prompt, context=context)\n",
    "\n",
    "    res = literal_eval(req)\n",
    "    # check if valid gpt res move\n",
    "    valid_res = is_legal_move(\n",
    "        board=board, move=chess.Move.from_uci(res['move']))\n",
    "\n",
    "    # info printings\n",
    "    if (debug):\n",
    "        print(f\"[------{row['PuzzleId']}------]\")\n",
    "        print(f\"[gpt-move | dataset-move] : {res['move']} | {last_move}\")\n",
    "\n",
    "    if (valid_res is not True):\n",
    "        print(f\"[{row['PuzzleId']}][valid-move] : {valid_res}\")\n",
    "        return\n",
    "\n",
    "    board_gpt = push_move(board=copy.deepcopy(\n",
    "        board), move=chess.Move.from_uci(res['move']))\n",
    "    return board_gpt.is_checkmate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = np.array([])\n",
    "\n",
    "# for training-dataset purposes\n",
    "# for index, row in train_df_one.iterrows():\n",
    "#     context = np.append(context, process_training_row(row))\n",
    "\n",
    "messages = np.array([\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"\"\"      \n",
    "                You are a chess engine playing that solves chess puzzles. \\\n",
    "                Your main task will be to solve chess puzzles.\n",
    "                \n",
    "                Therefore, I will provide you with board position in \\\n",
    "                'FEN (Forsyth–Edwards Notation)' format. Also all the \\\n",
    "                legal moves available for that FEN board in UCI (Universal \\\n",
    "                Chess Interface) format.\n",
    "                \n",
    "                The prompt input structure will be something like this:\n",
    "                \n",
    "                ```\n",
    "                    \"fen\": <fen>\n",
    "                    \"valid_moves\" : <valid_moves>\n",
    "                ```\n",
    "                \n",
    "                Your task is to choose one of the moves from the legal \\\n",
    "                moves list provided in the prompt that produces a mate \\ \n",
    "                in one to the provided FEN\n",
    "                                \n",
    "                Please do not provide any extra definition or information, just output \\\n",
    "                the movement in a JSON Object with the following format:\n",
    "                \n",
    "                ```\n",
    "                    \"move\": <your_move>\n",
    "                ```\n",
    "            \"\"\",\n",
    "    },\n",
    "])\n",
    "\n",
    "context = np.append(messages, context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dataframe that with the provided moves, the puzzle is completed\n",
    "# should be a redundant code as the dataset should be all puzzles completed\n",
    "# but just in case of some puzzle stored not done correctly.\n",
    "\n",
    "checkmate_df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "for index, row in df_one.iterrows():\n",
    "    board = chess.Board(row['FEN'])\n",
    "    chess_moves = [chess.Move.from_uci(move) for move in row['Moves'].split()]\n",
    "\n",
    "    for move in chess_moves:\n",
    "        if (move in board.legal_moves):\n",
    "            push_move(board=board, move=move)\n",
    "\n",
    "    if (board.is_checkmate()):\n",
    "        checkmate_df = pd.concat([checkmate_df, row.to_frame().T])\n",
    "    else:\n",
    "        print(row['PuzzleId'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate filename name, if it exists, it appends an index number\n",
    "# at the end of it.\n",
    "def build_filename(template, temperature, dir, model):\n",
    "    current_date = datetime.datetime.now().strftime(\"%d_%m\")\n",
    "    filename = f\"{current_date}-{template}-model-{model}-temp-{temperature}.txt\"\n",
    "    full_path = os.path.join(dir, filename)\n",
    "\n",
    "    index = 1\n",
    "    while os.path.exists(full_path):\n",
    "        new_filename = f\"{current_date}-{template}-model-{model}-temp-{temperature}_{index}.txt\"\n",
    "        full_path = os.path.join(dir, new_filename)\n",
    "        index += 1\n",
    "\n",
    "    return full_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./out/20_07-data-model-gpt-3.5-turbo-16k-temp-0.txt\n",
      "./out/20_07-/error/error-model-gpt-3.5-turbo-16k-temp-0.txt\n",
      "An error occurred while creating or writing to the file.\n"
     ]
    }
   ],
   "source": [
    "filename = build_filename(\n",
    "    template=TEMPLATE_FILE_PATH,\n",
    "    temperature=TEMPERATURE,\n",
    "    dir=OUTPUT_DIR,\n",
    "    model=MODEL,\n",
    ")\n",
    "\n",
    "error_filename = build_filename(\n",
    "    template=TEMPLATE_ERROR_FILE_PATH,\n",
    "    temperature=TEMPERATURE,\n",
    "    dir=OUTPUT_ERROR_DIR,\n",
    "    model=MODEL,\n",
    ")\n",
    "\n",
    "print(filename)\n",
    "print(error_filename)\n",
    "\n",
    "try:\n",
    "    error_file = open(error_filename, 'w')\n",
    "    with open(filename, 'w') as file:\n",
    "        for index, row in checkmate_df.iterrows():\n",
    "            try:\n",
    "              # only first 100 rows [testing]\n",
    "                if (index == 100):\n",
    "                    break\n",
    "\n",
    "                # list to store results\n",
    "                results = []\n",
    "\n",
    "                # 3 iterations for variability purposes\n",
    "                for i in range(3):\n",
    "                    result = process_test_row(\n",
    "                        row=row, context=context)\n",
    "                    results.append(result)\n",
    "\n",
    "                if (DEBUG is True):\n",
    "                    print(f\"[{row['PuzzleId']}]: { results }\")\n",
    "\n",
    "                # write content into file\n",
    "                file.write(f\"[{row['PuzzleId']}]: { results }\\n\")\n",
    "\n",
    "                # increase time in case of error *`ServiceUnavailableError: The server is overloaded or not ready yet.`*\n",
    "                time.sleep(10)\n",
    "            except Exception as e:\n",
    "                error_file.write(f\"[{row['PuzzleId']}]: { e }\\n\")\n",
    "\n",
    "        print(f\"Finished experiment and stored at {filename}\")\n",
    "except Exception as e:\n",
    "    print(\"An error occurred while creating or writing to the file.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

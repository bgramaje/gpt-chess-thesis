{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /home/balbert/.local/lib/python3.8/site-packages (0.27.8)\n",
      "Requirement already satisfied: tqdm in /home/balbert/.local/lib/python3.8/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: requests>=2.20 in /home/balbert/.local/lib/python3.8/site-packages (from openai) (2.28.1)\n",
      "Requirement already satisfied: aiohttp in /home/balbert/.local/lib/python3.8/site-packages (from openai) (3.8.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.20->openai) (2019.11.28)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/balbert/.local/lib/python3.8/site-packages (from requests>=2.20->openai) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.20->openai) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/balbert/.local/lib/python3.8/site-packages (from requests>=2.20->openai) (1.26.12)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/balbert/.local/lib/python3.8/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/balbert/.local/lib/python3.8/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/balbert/.local/lib/python3.8/site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/python3/dist-packages (from aiohttp->openai) (19.3.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/balbert/.local/lib/python3.8/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/balbert/.local/lib/python3.8/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: chess in /home/balbert/.local/lib/python3.8/site-packages (1.9.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-dotenv in /home/balbert/.local/lib/python3.8/site-packages (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai\n",
    "%pip install chess\n",
    "%pip install python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import os\n",
    "import openai\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import chess\n",
    "import copy\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "\n",
    "from ast import literal_eval\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe from downloaded dataset\n",
    "df = pd.read_csv('data/db.csv')\n",
    "# create dataframe of one move chess puzzles\n",
    "df_one = df[df['Themes'].str.contains('mateIn1')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt-4-0613', 'text-davinci-001', 'text-search-curie-query-001', 'davinci', 'text-babbage-001', 'curie-instruct-beta', 'text-davinci-003', 'gpt-3.5-turbo-16k-0613', 'davinci-similarity', 'code-davinci-edit-001', 'text-similarity-curie-001', 'text-embedding-ada-002', 'gpt-3.5-turbo-16k', 'ada-code-search-text', 'text-search-ada-query-001', 'gpt-4-0314', 'babbage-search-query', 'ada-similarity', 'gpt-3.5-turbo', 'whisper-1', 'text-search-ada-doc-001', 'text-search-babbage-query-001', 'code-search-ada-code-001', 'curie-search-document', 'text-search-davinci-query-001', 'text-search-curie-doc-001', 'gpt-3.5-turbo-0301', 'babbage-search-document', 'babbage-code-search-text', 'davinci-instruct-beta', 'davinci-search-query', 'text-similarity-babbage-001', 'text-davinci-002', 'code-search-babbage-text-001', 'babbage', 'text-search-davinci-doc-001', 'code-search-ada-text-001', 'ada-search-query', 'text-similarity-ada-001', 'gpt-4', 'ada-code-search-code', 'ada', 'text-davinci-edit-001', 'davinci-search-document', 'curie-search-query', 'babbage-similarity', 'ada-search-document', 'text-ada-001', 'text-similarity-davinci-001', 'curie', 'curie-similarity', 'gpt-3.5-turbo-0613', 'babbage-code-search-code', 'code-search-babbage-code-001', 'text-search-babbage-doc-001', 'text-curie-001']\n"
     ]
    }
   ],
   "source": [
    "# import environment variable into notebook\n",
    "_ = load_dotenv(find_dotenv())  # read local .env file\n",
    "# openai.api_key = ''\n",
    "# list openai available models given the api key.\n",
    "ids = [item[\"id\"] for item in (openai.Model.list())['data']]\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_move(board: chess.Board, move: chess.Move):\n",
    "    \"\"\" \n",
    "    args:\n",
    "        board (chess.Board)\n",
    "        moves (chess.Move)\n",
    "    \"\"\"\n",
    "    if board.is_legal(move):\n",
    "        board.push(move)\n",
    "    return board\n",
    "\n",
    "\n",
    "def is_legal_move(board: chess.Board, move: chess.Move) -> bool:\n",
    "    \"\"\" \n",
    "    Function that given a fen an a move checks\n",
    "    if the provided move is legal\n",
    "    args:\n",
    "        board (chess.Board)\n",
    "        moves (str)\n",
    "    returns:\n",
    "        bool  \n",
    "    \"\"\"\n",
    "    return board.is_legal(move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_filename(template, temperature, dir, model, ext=\"txt\"):\n",
    "    \"\"\"\n",
    "        generate filename name, if it exists, it appends an index number\n",
    "        at the end of it.\n",
    "    \"\"\"\n",
    "    current_date = datetime.datetime.now().strftime(\"%d_%m\")\n",
    "    filename = f\"{current_date}-{template}-{model}-{temperature}.{ext}\"\n",
    "    full_path = os.path.join(dir, filename)\n",
    "\n",
    "    index = 1\n",
    "    while os.path.exists(full_path):\n",
    "        new_filename = f\"{current_date}-{template}-{model}-{temperature}_{index}.{ext}\"\n",
    "        full_path = os.path.join(dir, new_filename)\n",
    "        index += 1\n",
    "\n",
    "    return full_path\n",
    "\n",
    "\n",
    "def build_columns(variability=3):\n",
    "    columns = []\n",
    "\n",
    "    columns.append(f\"puzzleId\")\n",
    "    columns.append(f\"datasetMove\")\n",
    "\n",
    "    for i in range(variability):\n",
    "        columns.append(f\"gpt{i}-move\")\n",
    "        columns.append(f\"gpt{i}-valid\")\n",
    "        columns.append(f\"gpt{i}-done\")\n",
    "\n",
    "    columns.append(f\"gpt-results\")\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dataframe that with the provided moves, the puzzle is completed\n",
    "# should be a redundant code as the dataset should be all puzzles completed\n",
    "# but just in case of some puzzle stored not done correctly.\n",
    "\n",
    "checkmate_df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "for index, row in df_one.iterrows():\n",
    "    board = chess.Board(row['FEN'])\n",
    "    chess_moves = [chess.Move.from_uci(move) for move in row['Moves'].split()]\n",
    "\n",
    "    for move in chess_moves:\n",
    "        if (move in board.legal_moves):\n",
    "            push_move(board=board, move=move)\n",
    "\n",
    "    if (board.is_checkmate()):\n",
    "        checkmate_df = pd.concat([checkmate_df, row.to_frame().T])\n",
    "    else:\n",
    "        print(row['PuzzleId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global constant variables\n",
    "\n",
    "# output dir to save data files\n",
    "OUTPUT_DIR = \"./out\"\n",
    "# name of files to append to filename\n",
    "TEMPLATE_FILE_PATH = \"data\"\n",
    "# type of extension for data files\n",
    "EXTENSION_FILE = \"csv\"\n",
    "\n",
    "# error files dir path\n",
    "OUTPUT_ERROR_DIR = \"./out/error\"\n",
    "# name of error files to append to error filename\n",
    "TEMPLATE_ERROR_FILE_PATH = \"error\"\n",
    "\n",
    "# openai variables\n",
    "\n",
    "TEMPERATURE = 1\n",
    "# AVAILABLE MODELS [gpt-3.5-turbo-16k, gpt-4, gpt-4-0613]\n",
    "MODEL = 'gpt-3.5-turbo-16k-0613'\n",
    "\n",
    "# config variables\n",
    "\n",
    "# increase time in case of error *`ServiceUnavailableError: The server is overloaded or not ready yet.`*\n",
    "REQ_INTERVAL = 5  # 10 sec\n",
    "VARIABILITY_TRIES = 3\n",
    "MAX_PUZZLES = 50\n",
    "\n",
    "# debug flag\n",
    "DEBUG = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request(\n",
    "    prompt=\"\",\n",
    "    context=np.array([]),\n",
    "):\n",
    "    \"\"\"\n",
    "    Helper function to make a request to openai api, and return it's response.\n",
    "    args:\n",
    "        prompt (string)\n",
    "        model (str)\n",
    "        temperature (int)\n",
    "    returns:\n",
    "        str\n",
    "    \"\"\"\n",
    "    context = np.append(\n",
    "        context,\n",
    "        np.array([{\n",
    "            \"role\": 'user',\n",
    "            \"content\": f\"\"\"\n",
    "                {prompt}\n",
    "            \"\"\",\n",
    "        }]), axis=0)\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=MODEL,\n",
    "        messages=context.tolist(),\n",
    "        temperature=TEMPERATURE,  # this is the degree of randomness of the model's output\n",
    "        max_tokens=10,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_row(row, context, temperature=0, debug=False):\n",
    "    # create chess board with 'fen' dataset\n",
    "    board = chess.Board(row['FEN'])\n",
    "    # create chess moves from 'uci' moves from dataset\n",
    "    chess_moves = [chess.Move.from_uci(move) for move in row['Moves'].split()]\n",
    "\n",
    "    # retrieve last move\n",
    "    last_move = chess_moves.pop()\n",
    "\n",
    "    # add all moves except the last one.\n",
    "    for move in chess_moves:\n",
    "        push_move(board=board, move=move)\n",
    "\n",
    "    # generate prompt\n",
    "    prompt = f\"\"\"\n",
    "        \"fen\": {board.fen()}\n",
    "        \"valid_moves\": { json.dumps([move.uci() for move in list(board.legal_moves)])}\n",
    "        \"history\": {json.dumps([move.uci() for move in list(chess_moves)])}\n",
    "    \"\"\"\n",
    "\n",
    "    # req to gpt model\n",
    "    req = request(prompt=prompt, context=context).replace(\" \", \"\")\n",
    "\n",
    "    if (debug):\n",
    "        print(f\"[gpt-response]: {req}\")\n",
    "\n",
    "    res = literal_eval(req)\n",
    "    # check if valid gpt res move\n",
    "    valid_res = is_legal_move(\n",
    "        board=board, move=chess.Move.from_uci(res['move']))\n",
    "\n",
    "    # info printings\n",
    "    if (debug):\n",
    "        print(f\"[gpt-move | dataset-move] : {res['move']} | {last_move}\")\n",
    "\n",
    "    if (valid_res is not True):\n",
    "        return {\n",
    "            \"completed\": False,\n",
    "            \"move\": res['move'],\n",
    "            \"valid\": valid_res\n",
    "        }\n",
    "\n",
    "    board_gpt = push_move(board=copy.deepcopy(\n",
    "        board), move=chess.Move.from_uci(res['move']))\n",
    "\n",
    "    return {\n",
    "        \"completed\": board_gpt.is_checkmate(),\n",
    "        \"move\": res['move'],\n",
    "        \"valid\": valid_res\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = np.array([])\n",
    "\n",
    "# for training-dataset purposes\n",
    "# for index, row in train_df_one.iterrows():\n",
    "#     context = np.append(context, process_training_row(row))\n",
    "\n",
    "messages = np.array([\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"\"\"      \n",
    "                You are a chess engine that solves chess puzzles. \n",
    "                Your objective is to do mate in one in the puzzle I provide you.\n",
    "                                    \n",
    "                The prompt input structure will be something like this delimited by the three backticks:\n",
    "                                    \n",
    "                 ```\n",
    "                \"fen\": <fen>\n",
    "                \"valid_moves\" : <valid_moves>\n",
    "                \"history\": <history>\n",
    "                ```\n",
    "\n",
    "                \"<fen>\" stands for chess board position in 'FEN (Forsyth–Edwards Notation)' format.\n",
    "                \"<valid_moves>\" stands for all legal moves available for that FEN board in UCI (Universal \\Chess Interface) format.\n",
    "                \"<history>\" stands for all the moves that has been played in that puzzle n UCI (Universal \\Chess Interface) format.\n",
    "                                    \n",
    "                Your task is to pick a move from the \"valid_moves\" list above\n",
    "                that maximizes your chance of doing checkmate.\n",
    "                                                    \n",
    "                Output the best move in UCI format to follow this position. Use the following single blob of JSON. Do not include any other information.\n",
    "            \n",
    "                ```\n",
    "                {{\"move\": <generated_move>}}\n",
    "                ```\n",
    "            \"\"\",\n",
    "    },\n",
    "])\n",
    "\n",
    "context = np.append(messages, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[exp-path] : ./out/08_08-data-gpt-3.5-turbo-16k-0613-1_1.csv\n",
      "[error-exp-path] : ./out/error/08_08-error-gpt-3.5-turbo-16k-0613-1_6.txt\n",
      "[001gi]: ['001gi', 'a5c3', 'h8g8', True, False, 'h8g8', True, False, 'd7e8', True, False, 'False False False']\n",
      "[001wb]: ['001wb', 'g6h5', 'e8g8', True, False, 'e8g8', True, False, 'e8f8', True, False, 'False False False']\n",
      "[002CP]: ['002CP', 'g6c2', 'g6h6', True, False, 'g6h8', False, False, 'g6h8', False, False, 'False False False']\n",
      "[003IX]: ['003IX', 'e4g3', 'g4g8', True, False, 'e7e8', True, False, 'g4g1', True, False, 'False False False']\n",
      "[004iZ]: ['004iZ', 'g3g7', 'd4g7', True, False, 'd4g7', True, False, 'd4g7', True, False, 'False False False']\n",
      "[004zI]: ['004zI', 'h6h8', 'h6h8', True, True, 'h6h8', True, True, 'h6h8', True, True, 'True True True']\n",
      "[008Nz]: ['008Nz', 'd1d8', 'd1d8', True, True, 'a5b6', True, False, 'h4h5', True, False, 'True False False']\n",
      "[008o6]: ['008o6', 'a8f8', 'f1f8', True, True, 'f1f8', True, True, 'a8f8', True, True, 'True True True']\n",
      "[009L0]: ['009L0', 'c1d1', 'e7e8', True, False, 'g8h8', True, False, 'b7c8', True, False, 'False False False']\n",
      "[00B2k]: ['00B2k', 'h4f2', 'g8h8', True, False, 'g8h8', True, False, 'f8e8', True, False, 'False False False']\n",
      "[00Bm8]: ['00Bm8', 'g6g2', 'g7h8', True, False, 'g7h8', True, False, 'g6f7', True, False, 'False False False']\n",
      "[00C7m]: ['00C7m', 'b4h4', 'f7f8', True, False, None, False, False, 'f7f8', True, False, 'False False False']\n",
      "[00DPQ]: ['00DPQ', 'g3h2', 'h8g8', True, False, 'h8g8', True, False, 'h8g8', True, False, 'False False False']\n",
      "[00FHX]: ['00FHX', 'c1c8', 'g2g4', True, False, 'g1f2', True, False, 'g1h2', True, False, 'False False False']\n",
      "[00G0z]: ['00G0z', 'f4h2', 'd6c7', True, False, 'd7f5', True, False, 'f4g3', True, False, 'False False False']\n",
      "[00GRa]: ['00GRa', 'e4h7', 'e4f5', True, False, 'e4h7', True, True, 'e4h7', True, True, 'False True True']\n",
      "[00H1C]: ['00H1C', 'a5c7', None, False, False, 'd7d8', True, False, 'a5c7', True, True, 'False False True']\n",
      "[00H9n]: ['00H9n', 'h3g2', 'h3d7', True, False, 'h8g8', True, False, 'h8g8', True, False, 'False False False']\n",
      "[00HHN]: ['00HHN', 'e8e1', 'e8g8', True, False, 'e8f8', True, False, 'e8g8', True, False, 'False False False']\n",
      "[00HPz]: ['00HPz', 'c6c5', 'g8f8', True, False, 'g8h8', True, False, 'g8f8', True, False, 'False False False']\n",
      "[00HoG]: ['00HoG', 'g6h7', 'g6g8', True, False, 'g6g8', True, False, 'g6g8', True, False, 'False False False']\n",
      "[00Hxb]: ['00Hxb', 'e1e8', 'c6e8', True, False, 'c6e8', True, False, 'f5h6', True, False, 'False False False']\n",
      "[00IPp]: ['00IPp', 'e3f3', 'e3g5', True, False, 'e3g5', True, False, 'e3e5', True, False, 'False False False']\n",
      "[00ITc]: ['00ITc', 'd4g7', 'd4g7', True, True, 'd4g7', True, True, 'd4d8', True, False, 'True True False']\n",
      "[00IaZ]: ['00IaZ', 'e8b8', 'e7f7', True, False, 'e8h8', True, False, 'e8h8', True, False, 'False False False']\n",
      "[00J7i]: ['00J7i', 'b7g7', 'c3d4', True, False, 'c3e5', True, False, None, False, False, 'False False False']\n",
      "[00JO7]: ['00JO7', 'h7h8', 'h3h6', True, False, 'h7h8', True, True, 'h7h8', True, True, 'False True True']\n",
      "[00KYE]: ['00KYE', 'd6h2', 'h8g8', True, False, 'd6d8', True, False, 'h8h7', True, False, 'False False False']\n",
      "[00MYL]: ['00MYL', 'f7b7', 'f7g8', True, False, 'b8h8', True, False, 'b8h8', True, False, 'False False False']\n",
      "[00OPk]: ['00OPk', 'd6f7', None, False, False, 'd6f7', True, True, 'd6e8', True, False, 'False True False']\n",
      "[00OXc]: ['00OXc', 'f3h3', 'f3f1', True, False, 'f3h3', True, True, 'f3h3', True, True, 'False True True']\n",
      "[00Or5]: ['00Or5', 'b3f7', 'b3g8', True, False, 'b3g8', True, False, 'e5f7', True, False, 'False False False']\n",
      "[00Ozz]: ['00Ozz', 'e1e8', 'f7g8', True, False, 'f7g8', True, False, 'f7g8', True, False, 'False False False']\n",
      "[00P7n]: ['00P7n', 'g4g7', 'g4g7', True, True, 'g4g7', True, True, 'g4g7', True, True, 'True True True']\n",
      "[00QY3]: ['00QY3', 'h3f1', 'g8h8', True, False, 'g8h8', True, False, 'g8h8', True, False, 'False False False']\n",
      "[00QZV]: ['00QZV', 'f5f1', 'c6b8', True, False, 'c6e7', True, False, 'c5f2', True, False, 'False False False']\n",
      "[00RoG]: ['00RoG', 'g4g1', 'g8h6', True, False, 'd8f8', True, False, 'd8h4', False, False, 'False False False']\n",
      "[00SMl]: ['00SMl', 'd5f6', None, False, False, 'd5e7', True, True, 'h1h8', True, False, 'False True False']\n",
      "[00SOy]: ['00SOy', 'h4h1', 'g8h7', True, False, 'h4h2', True, False, 'h4g3', True, False, 'False False False']\n",
      "[00STy]: ['00STy', 'b7b6', 'h7h8', True, False, 'h7h8', True, False, 'h7h8', True, False, 'False False False']\n",
      "[00SeK]: ['00SeK', 'd4g7', 'd4h8', True, False, 'd4h8', True, False, 'd4h8', True, False, 'False False False']\n",
      "[00SfT]: ['00SfT', 'h5h7', 'h5h8', True, False, 'h5h8', True, False, 'h5h8', True, False, 'False False False']\n",
      "[00T85]: ['00T85', 'f2d2', 'f2f1', True, False, 'f2f8', True, False, 'f2f8', True, False, 'False False False']\n",
      "[00VIe]: ['00VIe', 'a2d2', 'e3f4', True, False, 'h5h4', True, False, 'a2a1', True, False, 'False False False']\n",
      "[00ViT]: ['00ViT', 'g7g5', 'g8h8', True, False, 'd5c4', True, False, 'd5a8', True, False, 'False False False']\n",
      "[00X1l]: ['00X1l', 'f1f8', 'b3g8', True, False, 'a2a3', True, False, 'a7b8', True, False, 'False False False']\n",
      "[00X2S]: ['00X2S', 'a5c7', 'e5h8', True, False, 'e5h8', True, False, 'e5h8', True, False, 'False False False']\n",
      "[00Xfn]: ['00Xfn', 'h1h8', 'd4h8', True, False, 'g6h7', True, False, 'd4h8', True, False, 'False False False']\n",
      "[00Xiu]: ['00Xiu', 'h4e1', 'h4d8', True, False, 'b6c8', True, False, 'b6c4', True, False, 'False False False']\n",
      "[00Zh6]: ['00Zh6', 'e4f6', 'e5f7', True, False, 'e5f7', True, False, 'e5f7', True, False, 'False False False']\n",
      "Finished experiment and stored at ./out/08_08-data-gpt-3.5-turbo-16k-0613-1_1.csv\n"
     ]
    }
   ],
   "source": [
    "filename = build_filename(\n",
    "    template=TEMPLATE_FILE_PATH,\n",
    "    temperature=TEMPERATURE,\n",
    "    dir=OUTPUT_DIR,\n",
    "    model=MODEL,\n",
    "    ext=EXTENSION_FILE\n",
    ")\n",
    "\n",
    "error_filename = build_filename(\n",
    "    template=TEMPLATE_ERROR_FILE_PATH,\n",
    "    temperature=TEMPERATURE,\n",
    "    dir=OUTPUT_ERROR_DIR,\n",
    "    model=MODEL,\n",
    ")\n",
    "\n",
    "print(f\"[exp-path] : {filename}\")\n",
    "print(f\"[error-exp-path] : {error_filename}\")\n",
    "\n",
    "_df = pd.DataFrame(columns=build_columns(\n",
    "    VARIABILITY_TRIES)).reset_index(drop=True)\n",
    "\n",
    "try:\n",
    "    FILE = open(filename, 'w')\n",
    "    for index, row in checkmate_df.iterrows():\n",
    "        try:\n",
    "            # only first 100 rows [testing]\n",
    "            if (index == MAX_PUZZLES):\n",
    "                break\n",
    "\n",
    "            # list to store results\n",
    "            results = []\n",
    "            final_column = []\n",
    "            # store puzzle id\n",
    "            results.append(row['PuzzleId'])\n",
    "            # store dataset last move\n",
    "            results.append(row['Moves'].split().pop())\n",
    "\n",
    "            # 3 iterations for variability purposes\n",
    "            for i in range(VARIABILITY_TRIES):\n",
    "                try:\n",
    "                    result = process_test_row(\n",
    "                        row=row, context=context, debug=False)\n",
    "                    results.append(result['move'])\n",
    "                    results.append(result['valid'])\n",
    "                    results.append(result['completed'])\n",
    "                    final_column.append(result['completed'])\n",
    "                except Exception as e:\n",
    "                    results.append(None)\n",
    "                    results.append(False)\n",
    "                    results.append(False)\n",
    "                    final_column.append(False)\n",
    "\n",
    "                if (\"gpt-4\" in MODEL):\n",
    "                    time.sleep(REQ_INTERVAL)\n",
    "\n",
    "            results.append(' '.join(str(e) for e in final_column))\n",
    "\n",
    "            if (DEBUG is True):\n",
    "                print(f\"[{row['PuzzleId']}]: { results }\")\n",
    "\n",
    "            _df.loc[len(_df)] = results\n",
    "        except Exception as e:\n",
    "            if (DEBUG is True):\n",
    "                print(f\"[{row['PuzzleId']}]: { e }\")\n",
    "\n",
    "            ERROR_FILE = open(error_filename, 'w')\n",
    "            ERROR_FILE.write(f\"[{row['PuzzleId']}]: { e }\\n\")\n",
    "            ERROR_FILE.close()\n",
    "\n",
    "    print(f\"Finished experiment and stored at {filename}\")\n",
    "except Exception as e:\n",
    "    if (DEBUG is True):\n",
    "        print(f\"{ e }\\n\")\n",
    "\n",
    "_df.to_csv(filename, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
